% methodsandresults.tex

% Methods and Results
\section{Methods and Results}
\label{sec:methodsandresults}

The implementation constitutes the realization of the paravirtualized technology described in this document.
From the implementation, several concepts and phrases may be recognized and related to the Android Hardware OpenGL ES emulation design overview (see \dvtcmdciteref{technicaldocs:google:2014}).
In accordance to the Android emulator, paravirtualized graphics acceleration is achieved by the means of three overall components; being the Target System Libraries, the Host System Libraries, and the communications channel aptly named the Simics Pipe.
These components, along with elaboration on the methodologies accommodating them, are described in this chapter (see figure \ref{fig:overview} for an overview of the components and their relationships).

% OpenGL ABI Generation
\subsection{OpenGL ABI Generation}
\label{sec:proposedsolutionandimplementation_openglabigeneration}
For the purposes of ensuring scalability of the solution during development, a set of scripts automating the generation of library source code is used to compile the majority of the target - and host system libraries.
As such, a large amount of the OpenGL function definitions encoded and decoded by the components described in sections \ref{sec:proposedsolutionandimplementation_targetsystemlibraries} and \ref{sec:proposedsolutionandimplementation_hostsystemlibraries} are produced by this tool.
The functionality is implemented in a set of 	exttt{Python} scripts that, from a number of specification/configuration files detailing function signatures and argument attributes, generate both headers and source files in 	exttt{C}; thus collocating the target OpenGL and EGL ABIs, along with the corresponding host decoding libraries.
The tool generates all but the methods that need special treatment (due to state saving) and may thus generate methods with return values and inout arguments.
See figure \ref{fig:abigeneration} for an overview of the code generation process.

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{img/yedabigeneration.pdf}
  \caption[The ABI code generation process]{Visualization of the ABI code generating process performed to compile the target- and host system libraries.}
  \label{fig:abigeneration}
\end{figure}

\subsection{Target System Libraries}
\label{sec:proposedsolutionandimplementation_targetsystemlibraries}
The target system libraries are compiled from 	exttt{C} and 	exttt{C++}, and comprise implementations of the EGL - and OpenGL APIs.
Due to the tight coupling in-between OpenGL and the platform windowing system, the solution must also accelerate the Khronos EGL API - the interface between OpenGL and the underlying platform windowing system (see section \ref{sec:proposedsolutionandimplementation_windowingsystems} for an elaboration on the full extent of EGL interaction).
As may be derived from the name, the target system libraries run on the simulation target system and replace the existing Khronos libraries.

As such, the target systems libraries implement the EGL - and OpenGL~ES~$2.0$ APIs and lures whatever application it is being linked to that it is, in fact, the expected platform libraries.
Given that the target system libraries adheres to the OpenGL headers defined in the system, the application is na\"{\i}ve in terms of it's paravirtualized status.
The interplay with the original OpenGL~ES headers also results in the solution adhering to the platform-dependent type definition, flags, and constants; as originally defined by Khronos.
However, instead of communicating with the platform windowing system (in terms of EGL ) and the graphics device (in terms of OpenGL ) - and instructing said device in coagency with the user; the target system libraries rather serialize the given command stream and forwards it to the simulation host.
However, the transmission of the command stream is not necessarily performed at once, or in the designated order due to the formation of the OpenGL~ES~$2.0$ framework.
This complex of problems involve uncertainties of the proportion of argument data, as size is not necessarily specified by the user.
As such, certain serialization may have to be delayed until further information surrounding the argument dimensions have been relayed to the OpenGL library.
Furthermore, a subset of the OpenGL state need be maintained by the target system libraries.
These attributes are comprised by, inter alia, bound vertex- and index element buffers, in addition to properties of OpenGL vertex attributes.
Such states must be kept in the target system libraries due to the asynchronous nature of serialization of OpenGL invocations in the paravirtualized solution.

The serialization described in the above paragraph is thus formatted and encoded in accordance to a certain data format, which is kept as minimal as possible throughout execution.
This encoding includes packing variable length data types, such as $8$-bit characters, $16$-bit fields, or $64$-bit integer values, into fixed length structures, so that the host system may interpret these values independently of how corresponding types are defined on that unrelated platform\footnote{It should be noted, however, that the solution assumes a little endian architecture and IEEE 754 standard for floating point representation. If the host system would not conform to these prerequisites, the solution would have to be complemented with additional support.}.

% Host System Libraries
\subsection{Host System Libraries}
\label{sec:proposedsolutionandimplementation_hostsystemlibraries}
In collaboration with the target system libraries, the host system libraries - running on the host system - subsequently decodes and interprets the received byte stream.
Said decoding involves unpacking data from fixed length storage into variable-size types that the OpenGL - and EGL libraries expect.
Furthermore, and again similarly to the target system libraries, due to design inherent in the OpenGL~ES~$2.0$ framework, the host system libraries need maintain some data; in particular - vertex attributes.
Such data is buffered in the host system libraries until drawn in a later, and separate, OpenGL invocation\footnote{A possible optimization would be to cache said data, to avoid the need to transmit unmodified vertices multiple times, despite so being specified by the user.}.
When the requested OpenGL invocation has been performed, any return- or in-out values are returned to the target system using the Simics Pipe (see section \ref{sec:proposedsolutionandimplementation_simicspipe}).
As with the the target system libraries, the receiving end of an OpenGL method definitions in the host system libraries are likewise generated to a large degree.
The host system libraries are written in \texttt{C} and \texttt{C++}.

% Windowing Systems
\subsection{Windowing Systems}
\label{sec:proposedsolutionandimplementation_windowingsystems}
Due to variations in the creation and maintenance of windows on different platforms (i.e., Fedora 19 and Android ), incurred by said platforms utilizing different interfaces for the purpose, the window to which OpenGL renders is kept on the simulation host.
The problem may be summarized as the dilemma of the target system libraries having to communicate with the correct window (located in the simulation host ), yet having the target system window reporting successful initialization.
After all, it would be problematic if the OpenGL -utilizing application would have to be modified in order to be paravirtualized.
Effectively, this means that it would be desirable to maintain the native functionality of the target system EGL library.
However, in order to swap the backbuffers to which OpenGL renders (in the window present in the host system), one must use EGL methods.
In this way, the problem comprises a conflict in-between wanting to keep the functionality of the native EGL library, yet modify a small subset of it. 
This issue is overcome by the use of symbol overriding\footnote{Utilizing \dvtcmdcodeinline{LD_PRELOAD} on the Linux platform.}, which allows the target system libraries to overload a function, serialize and forward the invocation to the host system, locate the next occurrence of the symbol in the symbol table (being the original native EGL function definition), and invoke the original function.
As such, the target system EGL library does not replace the native target EGL library, as with the OpenGL library, but rather overloads some of its definition.
This gives the effect of a successfully created window, not having returned any errors in the window creation and maintenance - yet having the application actually communicating with a different window (present in the host system).
As such, the target system libraries are effectively performing a man-in-the-middle attack on the target EGL library.

In order to run the benchmarks described in section \ref{sec:experimentalmethodology_benchmarks}, the target system libraries need simply overload the \dvtcmdcodeinline{eglSwapBuffers} function, but the solution could easily be extended to listen in on requested window dimensions and other window attributes; effectively circumventing the need to heed any differences in-between platform-specific windowing systems.

% Simics Pipe
\subsection{Simics Pipe}
\label{sec:proposedsolutionandimplementation_simicspipe}
The so named 'Simics Pipe' constitutes the target -to-host communications channel in Simics.
As such, it is responsible for transferring a serialized command stream - or byte stream - to- and from the simulation host using magic instructions.
The role of the Simics Pipe is comprised of the allocation and maintenance of page locked target memory.
Furthermore, the Simics Pipe utilizes a magic instruction to relay the starting address of said memory space to the simulation host; where the responsibilities of the Simics Pipe end.

There are a numerous methodologies to communicate with the outside world from inside of the simulation, such as utilizing UNIX sockets or other networking technologies.
However, due to the inherent performance demands brought on by serialization of real-time graphics invocations, the methodology of magic instructions were selected for use for the purpose of this study.
Magic instructions allow for fast, in the pretext of the simulation target - almost instant - escape from the simulation context, and may carry a limited amount of information with it from inside the simulation out into the real world.
However, other - albeit slower, methodologies may be fast enough to for use in graphics paravirtualization; the Android emulator, in addition to magic instructions, supports TCP/IP communication\footnote{It may be of interest to know that the Simics OpenGL~ES paravirtualization technology, during development, was accommodated by a TCP/IP client-/server model.}.

In order to perform a magic instruction, the Simics Pipe uses \texttt{GCC} Extended Asm to directly inject \dvtcmdcodeinline{__volatile__}-flagged (as to prevent the compiler from reordering memory accesses during optimization) \texttt{assembly} instructions into 	exttt{C} code, in which - in addition to 	exttt{C++} - the Simics Pipe is written.
During said instruction, one may simply write an arbitrary 64-bit address to any register fit for the purpose (the number- and size of processor registers being the data-sharing bottleneck of the magic instruction paradigm).
Not being the first time magic instructions have been used for the purposes of hardware acceleration~\dvtcmdcitebib[p.~32]{publications:leupers:2010}, the Simics Pipe utilizes such methodology, namely the \dvtcmdcodeinline{CPUID} x86 instruction, to carry a lone memory address (being the address of the serialized command stream) in the target \dvtcmdcodeinline{rbx}\footnote{Accordingly, if the simulation target should correspond to a 32-bit x86 system, said register would translate to the \dvtcmdcodeinline{ebx} register.} register.
The execution of the injected instruction in a simulated processor, in line with the magic instruction paradigm, invokes a callback method in the host side of the Simics Pipe; having effectively escaped the simulation and paused the simulation state.
Knowing the occurrence of a magic instruction with the corresponding leaf number, one may assume the existence of a target memory address in the simulated target CPU register \dvtcmdcodeinline{rbx}.
Note that, at this point, the retrieved address is in the format of a target system virtual address; the destination of which is unknown to the simulation host.
As such, this address need be translated in order to retrieve the package contents said memory address points to.
See section \ref{sec:proposedsolutionandimplementation_pagetabletraversal} for more information on how the address is interpreted and how the entirety of the intended sequence of bytes is retrieved from target system primary memory.

\begin{figure}
\centering
\includegraphics[width=\linewidth]{img/yedoverview.pdf}
\caption[Paravirtualization implementation overview]{Overview of the implementation accomodating paravirtualized graphics in Simics.}
\label{fig:overview}
\end{figure}


% Page Table Traversal
\subsection{Page Table Traversal}
\label{sec:proposedsolutionandimplementation_pagetabletraversal}
As outlined in section \ref{sec:proposedsolutionandimplementation_simicspipe}, target -/host memory sharing in the Simics Pipe is performed by the means of exposing a target virtual address to the simulation host.
Said virtual address is, understandably so, only valid in the simulated system and bears no relevance in the real world; outside of the fact that the data to which the virtual address refers - in the target system - is, in turn, hidden behind layers of abstraction somewhere in host system memory.

Using Simics to utilize the MMU of the target system, one may translate a target virtual address (or 'virtualized virtual address') to a (target ) physical device address; to-/from which - again, using Simics - we may access an arbitrary number of bytes in physical memory.
However, due to the complexity induced by circumventing the abstraction of virtual memory, there is no guarantee that the memory page to which the exposed physical address refers has not been swapped out of primary memory.
In order to solve this, using some OSs (e.g., Fedora 19 \footnote{Using the \dvtcmdcodeinline{MAP_LOCKED} flag during invocation of the Linux \dvtcmdcodeinline{mmap}-system call; alternatively using the specific \dvtcmdcodeinline{mlock}-system call.}), one may 'lock' pages in order to prevent them from being swapped to disk.
This is the methodology used to ensure that the physical memory space, referred to by the virtual address sent to the simulation host, is still existent in target primary memory when the simulation state has been paused\footnote{Other methods to achieve this include repeatedly 'polling' the corresponding memory pages in the target system before inducing the simulation context switch to the host system.}.
Furthermore, and again induced by the unorthodox circumvention of the virtual memory paradigm, it is probable that the multiple memory pages making out particularly large serialized command streams, such as the transmission of vertex or texture data, are not consecutively aligned in physical memory, although guaranteed to be continuous blocks in terms of virtual memory.
As such, the physical addresses of memory pages must be continuously retrieved and translated on a per-page basis; effectively 'traversing' the virtual memory table (see figure \ref{fig:virtualmemory}).
This can be done in a trivial manner by simply iterating the original virtual address with the \textit{target } page size, in our case, $4096$ bytes.
Naturally, said process must be performed regardless of data being read or written to-/from the intended - physical - memory space.

\begin{figure}
\centering
\includegraphics[width=\linewidth]{img/yedvirtualmemory.pdf}
\caption[Memory translation overview]{Memory translation overview. The OpenGL process hands a virtual memory address, pointing somewhere in the target system \textit{primary} memory, to the paravirtualized solution - which inquiries the target system MMU to retrieve designated bytestream directly from target physical memory.} % \footnote{Observe that said bytestream may not be present in secondary storage, due to memory page locking.}
\label{fig:virtualmemory}
\end{figure}

\subsection{Experimental Methodology}
\label{sec:experimentalmethodology}
From this chapter onward, the term 'experiment' is used to refer to the experimental methodology put in place to answer the question formulations phrased in chapter \ref{cha:aimsandobjectives}.
The author would like to emphasize that the terminology is simply used to denote a method of experimentation to answer, that is verify or refute the validity of the hypotheses that may be intrinsically derived from-, the research questions outlined in chapter \ref{cha:aimsandobjectives}.
As such, 'experiment' does not refer to controlled-, natural-, or field experiment methodologies, or indeed any other specific method for experimentation unless specified otherwise.
The author reserves the right to use the following terminology interchangeably: study, case study, and experiment.

As such, the terminology used to describe the experimental methodology produced for the purpose of this study, henceforth referred to as 'the experiment', is not meant to be indicative of the method quality, or in any way indirectly describe said experimental methodology.
Below, the methods used to perform the experiment are presented.

% Platform Configuration
\subsubsection{Platform Configuration}
\label{sec:experimentalmethodology_platformconfiguration}
The experiment devised for the purpose of this dissertation is performed in software rasterized- and paravirtualized Simics platforms, respectively.
Furthermore, the experiment profiles the performance of the Android emulator to relate the devised solution to pre-existing technologies, in addition to execution on the hardware accelerated host platform as a reference case.
The following paragraphs outline the configuration of these target platforms, in terms of host configuration, simulated hardware, and the software configuration of the simulated systems.

% Host Configuration
\paragraph{Host Configuration}
\label{par:experimentalmethodology_platformconfiguration_hostconfiguration}
The system upon which the experiment is performed is an x86 -compatible Haswell Intel\circledR processor configured to run the Fedora 19 Linux distribution.
Said OS was selected for use due to Fedora 19 being the primary platform used for development of the Simics full-system simulator at the Intel\circledR offices in Stockholm - at which the solution described in this document has been developed.

% Target Hardware Configuration
\paragraph{Target Hardware Configuration}
\label{par:experimentalmethodology_platformconfiguration:targethardwareconfiguration}
The Simics hardware configuration utilized for the purpose of this experiment simulates an Intel\circledR\ Core	exttrademark\ i7; the same processor series to that of the actual hardware of the simulation host system.
Furthermore, Simics execution, both the software rasterized and paravirtualized platforms, utilize KVM for the simulation target to run natively on the host hardware.
In order to accommodate for similar acceleration in QEMU, Android is configured to run on the Intel\circledR Android x86 system image (see \dvtcmdciteref{technicaldocs:intel:2013:x86}), circumventing the need to interpret ARM instructions~\dvtcmdciteref{web:stylianou:2010}.
Furthermore, the solution also utilize KVM in order to provide similar native execution on the host hardware\footnote{Had the solution been running on the Windows OS, the solution would have utilized Intel\circledR\ HAXM (see ~\dvtcmdciteref{technicaldocs:intel:2013:haxm}) to accommodate for said native execution~\dvtcmdciteref{web:hofemeier:2010}.}.

% Target Software Configuration
\paragraph{Target Software Configuration}
\label{par:experimentalmethodology_platformconfiguration_targetsoftwareconfiguration}
In line with Fedora $19$ being the OS in use when performing the reference benchmark experiments on the host platform (see paragraph \dvtcmdrefname{par:experimentalmethodology_platformconfiguration_hostconfiguration}), it may be of value to have the simulated target machine configured to run with the same OS.
As such, the platform OSs used for the purpose of this study are as follows:
\begin{itemize}[noitemsep]
	\item Hardware accelerated Fedora $19$ host system
	\item Software rasterized\footnote{Using the Mesa OpenGL software rasterization implementation.} Fedora 19 Simics target system
	\item Paravirtualized Fedora $19$ Simics target system
	\item Paravirtualized Android $4.4$\footnote{Android KitKat - API level $19$.} QEMU target system
\end{itemize}

% Benchmarks
\subsubsection{Benchmarks}
\label{sec:experimentalmethodology_benchmarks}
Throughout the course of the pilot study, no existing OpenGL~ES~$2.0$ benchmark (featuring cross-platform profiling support for Android and X11 Linux ) was deemed appropriate for for the purposes of this experiment.
As such, a number of benchmarks have been devised on-site for the purposes of stress-testing the paravirtualized technology described in this document.
The benchmarks, numbering three in total, are intended to stress suspected bottlenecks in the implementation; corresponding to a large number of relatively insignificant OpenGL~ES invocations, computationally intensive GPU kernels, and passing of large data such as textures or models.
Since the benchmarks are required to run in both Linux - and Android platforms, the benchmarking suite utilize Java native interface to invoke OpenGL~ES from the same 	exttt{C} code base independent of platform.
Effectively, this entails having the benchmarks produced using \texttt{Java}, \texttt{C}, and \texttt{GLSL}, collectively.
Furthermore, all benchmarks are configured to run at roughly $16$~\milli\second , which would correspond to roughly $60$~frames per second, when hardware accelerated on the host system.
The benchmarks are devised in this way in order to reflect the expected load of a modern real-time interactive application.
As such, the purpose of developed benchmarks is to be representative of typical scenarios induced by modern graphics applications whilst utilizing a graphics framework such as OpenGL.
When run during the experiment, each benchmark instance measures the elapsed time of $1000$ frames which makes up the data subsequently analyzed.
Frame captures of the benchmarks are presented in figures \ref{fig:benchmarks_chess}, \ref{fig:benchmarks_julia}, and \ref{fig:benchmarks_phong}.

\begin{figure}
  \minipage{0.32\linewidth}
  \includegraphics[width=\linewidth]{img/imgchess.png}
  \caption[Chess benchmark screen capture]{Chess.}
  \label{fig:benchmarks_chess}
  \endminipage\hfill
  \minipage{0.32\linewidth}
  \includegraphics[width=\linewidth]{img/imgjulia.png}
  \caption[Julia benchmark screen capture]{Julia.}
  \label{fig:benchmarks_julia}
  \endminipage\hfill
  \minipage{0.32\linewidth}
  \includegraphics[width=\linewidth]{img/imgphong.png}
  \caption[Phong benchmark screen capture]{Phong.}
  \label{fig:benchmarks_phong}
  \endminipage
\end{figure}

% Benchmark: Chess
\paragraph{Benchmark: Chess}
\label{par:experimentalmethodology_benchmarking_benchmarkchess}
\index{Chess benchmark}
The 'Chess' benchmark is developed for the purposes of stressing the latency in-between target - and host systems.
It is so named because of the chess-like tileset the graphics kernel produces.
The benchmark is designed to perform a multitude of OpenGL~ES~$2.0$ library invocations per frame; in which each invocation is relatively lightweight in execution and carry a small amount of data argument-wise.
In the Chess benchmark, this is achieved by rendering a grid of colored (black or white, in order to adhere to the chess paradigm) rectangles where each tile is represented by four two-dimensional vertices in screen-space, in addition to six indices outlining the rectangular shape.
Since the vertices are already transformed into screen-space, the graphics kernel need perform no additional transformation, adhering to the desired lightweight behavior of each kernel invocation.
Additionally, the tileset vertices and indices are pre-loaded into OpenGL vertex- and index element buffers, so that a lone buffer identifier may be carried over in-place of the heavier vertex set load.
Each tile is then individually drawn to the backbuffer, rendering the chess-like appearance of the benchmark.
Effectively, this means that, for each tile, the benchmark need only bind a vertex- and an index element buffer, set the corresponding tile color, and lastly invoke the rendering of said tile.

For each frame rendered, depending on the number of drawn tiles, the solution will perform a large number of magic instructions.
This induces a high utilization of the Simics Pipe, which is intended to stress magic instruction overhead (section \ref{sec:results_magicinstructionoverhead}).
The repeated invocation of lesser draw calls is representative of common usage of drawing a multitude of shapes with OpenGL, such as a user interface. Additionally, the number of tiles being computed is easily modifiable; rendering the benchmark scalable for the purposes of the experiment described in this document. As such, said benchmark is considered suitable for the purpose of representing a large number of graphics invocations using OpenGL~ES~$2.0$.

% Benchmark: Julia
\paragraph{Benchmark: Julia}
\label{par:experimentalmethodology_benchmarking_benchmarkjulia}
\index{Julia fractal benchmark}
The 'Julia' benchmark is developed for the purposes of stressing computational intensity in software-rasterized and paravirtualized platforms.
It is so named due to the kernel calculating the Julia fractal; the texturing and frame-wise seeding of which gives the benchmark it's distinct look.
The benchmark is designed to perform a lone computationally intensive graphics kernel invocation, which will stress the computational prowess of the profiled platform.
The case is selected for use as the computation of a fractal is trivially scalable in terms of complexity, by modifying the number of iterations the fractal algorithm performs, and is thus considered suitable for profiling of computationally intensive graphics kernels.

% Benchmark: Phong
\paragraph{Benchmark: Phong}
\label{par:experimentalmethodology_benchmarking_benchmarkphong}
\index{Phong shading benchmark}
The 'Phong' benchmark is developed for the purposes of stressing the throughput, or bandwidth - if adhering to the networking paradigm, in-between target - and host systems.
The Phong benchmark is comprised of a rotating model, being the Newell teapot, which is textured and subsequently shaded by a single point light using the Phong shading model; thus giving the benchmark it's name. % \todo{point out as to why the newell teapot is a standard model}

The rasterization and shading of a model with a given, large, texture is representative of three-dimensional graphics commonly rendered with graphics frameworks such as OpenGL~ES~$2.0$.
As such, said benchmark is suitable for the purposes of representing the usage of big data (being models, textures, etc.).
For the purposes of stressing the bandwidth of target - and host communication, the Phong benchmark is easily scalable in terms of resizing the large texture in question.
Vertices and indices of the model do not utilize OpenGL vertex- and-/or index element buffers, thus forcing the solution to transmit the data every frame.
Additionally, in order to further stress the throughput of the profiled platform, texture data is updated every frame.

% Input Data Variation
\subsubsection{Input Data Variation}
\label{sec:experimentalmethodology_inputdatavariation}
In order to detect anything but linear potential of scaling in software rasterized- and paravirtualized Simics platforms, the benchmarks are configured to run in three separate instances, respectively.
These benchmark versions differ in terms of input data; where said input is a changed variable that could potentially worsen benchmark performance (e.g., larger texture).
The purpose of these 'input data variations' is to detect any unexpected results in execution; and thus identify any performance complexity issues in software rasterized- and paravirtualized Simics platforms.
For consistency, each benchmark variation - of which there are two; resulting in three unique experiments per benchmark - have been produced to halve- and subsequently double the corresponding input data.
The described input data, for each benchmark, is presented in table \ref{tab:keyvals}.
Consequently, in table \ref{tab:keyvalsmagicinstructions}, the per-frame number of magic instructions induced by these input data variations are presented, differing only for the Chess benchmark.

% Renders a table defining the key figures used for benchmark
% variations for the purpose of the experimend performed for this
% dissertation.
\begin{table}
  \centering
  \begin{tabular}{lllll}
    Benchmark & Input Data & Halved Input & Ref. Input & Double Input \\ \hline
    Chess & No. Tiles & $60\times60$ & $84\times84$ & $118\times118$ \\
    Julia & No. Iterations & $225$ & $450$ & $900$ \\
    Phong & Texture Resolution & $1448\times1448$ & $2048\times2048$ & $2896\times2896$ \\
  \end{tabular}
  \caption[Input data variations]{Input data used for benchmark variations for each benchmark.}
  \label{tab:keyvals}
\end{table}

% Renders a table defining the number of magic instructions performed
% for the benchmarks used in this experiment.
\begin{table}
  \centering
  \begin{tabular}{lllll}
    Benchmark & \phantom{Input Data} & Halved Input & Ref. Input & Double Input \\ \hline
    Chess & \phantom{No. Tiles} & $32403$ & $63507$ & $125319$ \\
    Julia & \phantom{No. Iterations} & $16$ & $16$ & $16$ \\
    Phong & \phantom{Texture Resolution} & $17$ & $17$ & $17$ \\
  \end{tabular}
  \caption[Input data variation magic instruction count]{Number of magic instructions performed per-frame for each benchmark input data variation.}
  \label{tab:keyvalsmagicinstructions}
\end{table}

Note that for each tile rendered in the Chess benchmark, the solution will perform $9$ magic instructions; entailing a total of $32400$\footnote{$9\times60\times60=32400$.}, $63504$\footnote{$9\times84\times84=63504$.}, and $125316$\footnote{$9\times118\times118=125316$.} magic instructions, respectively, in addition to a minor number per-frame.

