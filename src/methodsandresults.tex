% methodsandresults.tex

% Methods and Results
\section{Methods and Results}
\label{sec:methodsandresults}
OpenGL paravirtualization in Simics encompasses three overall components: the target system libraries, the host system libraries, and a communications channel between them named the "Simics pipe".
Most OpenGL glue code, on both target and host, is generated by a program from specification files detailing function signatures and arguments.
An exception is methods that require state saving, which are implemented manually.

The target system libraries implement the OpenGL and EGL (the interface between OpenGL and the underlying platform windowing system) APIs; unmodified binaries in the target system are subsequently linked with these libraries as with any other OpenGL or EGL implementation.
However, instead of communicating with the graphics device, the target system libraries serialize and forward the command stream to the simulation host.
The transmission is not necessarily performed at once, nor in the designated order, because of uncertainties regarding argument data proportion.
For instance, the number of vertices to be rendered does not have to be apparent at a given time, but implicit in a later OpenGL invocation.
Accordingly, certain function calls have to be delayed until more information is known about the OpenGL state.

In collaboration with the target system libraries, the host system libraries decode and interpret the received byte stream.
Subsequently, the host system libraries may safely perform the relayed workload and return any results to the target system.

Both target and host system libraries maintain a subset of the OpenGL state, such as bound vertex buffers and attribute properties.
These states must be maintained because of the asynchronous nature of the command stream.

Because of differences in the creation and maintenance of windows on different platforms (Fedora, Android, etc.), the window to which OpenGL renders is kept on the simulation host.
This is problematic; the target system libraries must communicate with a fraudulent window in the simulation host -- \textit{and} the native window.
For example, it is important that the native window reports successful initialization, lest the OpenGL application concludes an error and quits.
The issue is overcome by selectively overriding symbols in the target libraries so that a subset of functions may be overloaded.
This way, one may extend the original EGL library to invoke the simulation host prior to performing its actions.

To communicate with the simulation host, the Simics pipe uses "magic instructions".
A magic instruction is a \masccodeinline{nop} instruction that invokes a callback-method in the simulation host when executed on simulated hardware~\masccite[p.~32]{publications:leupers:2010}.
Because of the inherent performance demands brought on by real-time graphics, they constitute a suitable communications medium for rendering information between target and host systems.

During a magic instruction, we may utilize any available registers; the number and size of registers is the data-sharing bottleneck of this method.
Thus, we transmit the starting address of the serialized command stream in a 64-bit register.
Having escaped the simulation context, Simics can translate the transmitted virtual address to a physical one using the virtual machine MMU.
Consequently, the physical address can be used to locate the memory page in the simulated RAM image.
The pages constituting the buffer are locked in RAM, protecting the buffer from being paged to the swap area.
This ensures that pages are not swapped to disk when the simulation state is paused.
Subsequently, all memory pages are continiously retrieved by iterating the original virtual address with the target page size, effectively traversing the virtual memory table.

\subsection{Experimental Methodology}
\label{sec:experimentalmethodology}
To evaluate the implementation, performance of paravirtualized graphics in Simics is compared to software rasterization.
Simics itself simulates an Intel\circledR ~Core\texttrademark ~i7 processor and an Intel\circledR ~X58 chipset.
Throughout simulation, hardware-assisted virtualization using KVM runs x86 instructions natively on the host hardware.
Like the host system, the simulation target runs Fedora~$19$ Linux and use the Mesa llvmpipe driver software rasterizer~\masccite{web:mesa:2015}.

The experiments are performed on a system with the following specifications:
\begin{itemize}
\item Intel\circledR\ Core\texttrademark\ i7-4770HQ
\item Intel\circledR\ Iris\texttrademark\ Pro Graphics 5200
\end{itemize}

Two benchmarks are devised on-site to stress suspected bottlenecks: one benchmark performs a large number of OpenGL invocations, while the other has a computationally intensive workload.
Given a target frame time of $16$~\milli\second , the benchmarks are configured to run at $10$ to $20$~\milli\second\ per frame, when hardware accelerated on the host system; a $16$~\milli\second\ frame time roughly corresponds to $60$~frames per second.
The benchmarks are shaped this way to reflect the expected load of a real-time interactive application.
As such, the benchmarks should be representative of typical scenarios induced by modern applications using OpenGL, such as responsive UIs.
The developed benchmark suite is open source~\masccite{web:intel:2014}.

For each benchmark, the elapsed times of $1000$ frames are collected.
To gain some understanding on how well the given performance scales, three instances of each benchmark are run with smaller and larger input data, tuned to yield approximately half and double frame time.
The specifics of each benchmark are described below.

\input{src/tables}

% Benchmark: Chess
\paragraph{Benchmark: Chess}
\label{par:experimentalmethodology_benchmarking_benchmarkchess}
To stress the latency between target and host systems, the 'Chess' benchmark performs a multitude of lightweight OpenGL invocations per frame, rendering a grid of chess-like tiles.
For each frame rendered, depending on the number of tiles, the benchmark performs a large number of magic instructions.
This induces high utilization of the Simics Pipe, which is intended to stress suspected magic instruction overhead.

A long sequence of draw calls is representative of drawing multitudes of shapes with OpenGL, such as a UI.
Accordingly, the benchmark is suitable for the purpose of representing a large number of graphics invocations.

The Chess benchmark is run with $60\times60$, $84\times84$, and $118\times118$ tiles, which entails $9\times60\times60$, $9\times84\times84$, and $9\times118\times118$ magic instructions per frame.

% Benchmark: Julia
\paragraph{Benchmark: Julia}
\label{par:experimentalmethodology_benchmarking_benchmarkjulia}
To stress the computational prowess of paravirtualized graphics in Simics, the 'Julia' benchmark performs a lone, computationally intensive, OpenGL invocation that renders the Julia fractal~\masccite{web:tsiombikas:2014}.
The load of a fractal computation can easily be tuned by adjusting the number of iterations per pixel.
Therefore, the Julia benchmark is suitable to profile a computationally intensive workload. % TODO: This sentence might be redundant. Remove?

The Julia benchmark is run with $225$, $450$, and $900$ iterations, all of which induce $16$ magic instructions per frame.

\subsection{Threats to Validity}
\label{sec:threatstovalidity}
Because of complications caused by virtual time, measuring time in system simulation sometimes dictate special measures.
For instance, in terms of real-time rendering, the observer is far more interested in a frame rate relative to wall-clock time rather than virtual time.

In order to measure frame time in relation to wall-clock time, profiling must take place outside of the simulation.
One way of achieving this is to listen in on activity passing through a target serial port; this is a traditional front-end to the machine.
In this way, a simulation breakpoint can be triggered at the occurrence of a certain sequence of bytes written to a UART serial port.
This is the method used to measure frame time in Simics.

When using serial ports in this manner, one may introduce a profiling cost.
For example, file descriptors do not immediately transmit a byte sequence over the system UART.
For our set-up, we measure this overhead cost to be, on average, $1.5$~\milli\second .
This average is substracted from presented measurements.

\subsection{Results}
\label{sec:results}
Results accumulated from software rasterized and paravirtualized execution are presented in Tables~\ref{tab:keyvalsimics}~and~\ref{tab:keyvalpara}.
In Figure~\ref{fig:histogram}, the results are presented as histograms, visualizing elapsed time in milliseconds to sample density.
For each experiment, collected frame time samples ($1000$) are subdivided into $100$ bins.
Any measurements outside of the standard deviation are not included in the figures.

Figure~\ref{fig:histogram} indicates that the Chess benchmark, when software rasterized, yields a broad sample distribution, seemingly distributed around a single point.
The right-hand side of the graph, showing impaired performance induced by paravirtualization, visualize a distribution decrease.
This is supported by the data presented in Table~\ref{tab:keyvalpara}.
We observe that software rasterization outperforms its paravirtualized counterpart, regardless of the number of tiles rendered.
The benchmark is devised to identify any bottlenecks related to the number of paravirtualizaed invocations.
Evidently, the prediction of a target-to-host communication latency issue is confirmed.

In Simics, magic instructions incur a context switch cost when resuming execution on the host.
This causes the simulation to no longer execute natively, which inhibits performance imrovements granted by hardware-assisted virtualization.
It also entails that Simics can no longer utilize JIT, forcing the simulator to rely on interpretation.
As such, in great numbers, magic instructions may affect performance.

By measuring the elapsed time of using magic insructions to escape simulation $1000$ times, we conclude that $1000$ consecutive magic instructions induce an average overhead of $5$~\milli\second\ (not taking into account any profiling cost).
These findings indicate that magic instruction overhead could account for the majority of elapsed frame time.

Figure~\ref{fig:histogram} shows that the Julia benchmark yields double to triple peak sample density destribution, both in software rasterized and paravirtualed Simics.
What causes this behavior is unclear; the fractal algorithm should perform roughly equally frame-to-frame.
The benchmark is intented to demonstrate how paravirtualization performs under computational stress.
This is where the benefits of hardware acceleration should be made apperent.
Accordingly, weaknesses in software rasterization is highlighted with frame times above the two second mark; corresponding maximum paravirtualized frame time measuring a mere $156$ \milli\second.
This confirms performance improvements of using paravirtualization, paired with magic instructions, to accelerate graphics.

These measurements are collected using hardware-assisted virtualization for accelerated virtualization.
If hardware-assisted virtualization is not available, such as if the simulated platform is other than x86, we expect a major hit to performance.
For software rasterization, this impact accounts for frame time increases well over two orders of magnitude.
Meanwhile, performance impacts to paravirtualization is often not significant, sometimes as low as a third of the original frame time.
For the Chess benchmark, paravirualized frame time increase with \textit{up to} one order of magnitude, one order less than the performance hit to software rasterization.
Across the board, paravirtualization suffer less performance impact, rendering the benchmarks up to three orders of magnitude faster than software rasterization.
We conclude that the effects of paravirtualization increase by one order of magnitude without hardware-assisted virtualization.
This entails that workloads that are otherwise sub-optimal for paravirtualization -- those performing a large amount of function invocations -- bring about performance improvements when utilizing paravirtualization.
Thus, the impact of magic instruction overhead is reduced, likely because a costly context switch is not inflicted on Simics.
We reason that some software rasterized worklads (Chess) may attain decent simulation performance simply because of a fast simulator; when native execution is not available, neither JIT nor interpretation may attain the same speeds as paravirtualization.

The samples collected without hardware-assisted virtualization are not presented in detail, since the scenario of native execution is far more likely.
