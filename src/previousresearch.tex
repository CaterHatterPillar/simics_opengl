% previousresearch.tex

% Previous Research
\section{Previous Research}
\label{sec:previousresearch}
System simulators are abundant and exist in corporate~\dvtcmdcitebib{magazines:bohrer:2004}, academic~\dvtcmdcitebib{journals:rosenblum:1995}, and open-source variations~\dvtcmdciteref{magazines:bartholomew:2006}.
Such platforms, like Simics, have been used for a variety of purposes including, but not limited to, thermal control strategies in multicores~\dvtcmdcitebib{inproceedings:bartolini:2010}, networking timing analysis~\dvtcmdcitebib{journals:ortiz:2009}, web server performance evaluation~\dvtcmdcitebib{journals:villa:2005}, and to simulate costly hardware financially unfeasible to researchers~\dvtcmdcitebib{journals:alameldeen:2003}.
Furthermore, these simulators may also be used to port OSs to new processors~\dvtcmdciteref{technicaldocs:netbsd:2014}.

For the purposes of graphics acceleration in virtual platforms, strategies are numerous.
From a number of core strategies, such as device modeling, passthrough technologies, and paravirtualization, there are several attempts at accelerating simulator graphics; many of which require modification of both target and host systems.
One such instance is presented by Hansen in his work on the Blink display system~\dvtcmdcitebib{inproceedings:hansen:2007}.
Another is VMGL by Lagar-Cavilla et al., who accelerates OpenGL~$1.5$ roughly two orders of magnitude using paravirtualization~\dvtcmdcitebib{inproceedings:lagarcavilla:2007}.

QEMU ('Quick~Emulator') is an open-source virtual platform described as a full system emulator~\dvtcmdcitebib[p.~1]{inproceedings:bellard:2005} and a high-speed functional simulator~\dvtcmdcitebib[p.~1]{inproceedings:shen:2010}.
As such, QEMU may run unmodified target software such as OSs, drivers, and other applications~\dvtcmdcitebib[p.~1]{inproceedings:bellard:2005}.
The platform is widely used in academia, and is the subject of several articles and reports cited throughout this document.
Additionally, QEMU powers the Android emulator, which helps mobile developers bring about software for the Android OS.
The Android emulator accelerates OpenGL~ES~$1.1$ and $2.0$, granting developers significant performance boosts~\dvtcmdciteref{web:ducrohet:2012:afasteremulator}.

Other promising GPU virtualization projects include the Virgil3D-project~\dvtcmdciteref{technicaldocs:qemudevel:2014}.
As described at the project homepage, the project strives to create a virtual GPU which may utilize host hardware to accelerate 3D rendering.
Other related works include modeling GPU devices in the QEMU full-system simulator with software OpenGL~ES rasterization support, as presented by Shen et al.~\dvtcmdcitebib{inproceedings:shen:2010}.
At the time of writing, graphics virtualization is no longer limited to the academic community as big virtualization players incorporate various graphics acceleration solutions in their products.
One such example is VMware,~Inc.~\dvtcmdciteref{technicaldocs:vmware:2014}.

% Simics
\subsection{Simics}
\label{sec:simics}
Simics is a full-system simulator developed by Intel\circledR\ and sold through Intel\circledR 's subsidiary Wind~River~Systems,~Inc.
Simics was developed by the simulation group at the Swedish Institute of Computer Science, which was the first academic group to run an unmodified OS in an entirely simulated environment.
The product was was commercially launched by Virtutech in $1998$~\dvtcmdcitebib{journals:magnusson:2013} and subsequently acquired by Intel\circledR\ in $2010$~\dvtcmdciteref{web:miller:2010}.

As an architectural simulator, Simics' primary client group is software and systems developers that produce software for complex systems involving software and hardware interaction~\dvtcmdcitebib{journals:aarno:2013}.
For that reson, key attributes of Simics are scalability, repeatability, and high-performance simulation.
The simulator utilizes hardware-assisted virtualization and other performance boosting technologies such as hypersimulation~\dvtcmdcitebib[p.~38]{publications:leupers:2010} to accelerate simulation speeds.
Simics also feature advanced functionalities adhering to the deterministic nature of the simulator, such as checkpointing and reverse execution~\dvtcmdcitebib{publications:leupers:2010}.

The ability to simulate the entirety of an unmodified software stack has led to Simics being used to simulate a variety of systems including, but not limited to, single-processor embedded boards, multiprocessor servers, and heterogeneous telecom clusters~\dvtcmdcitebib{journals:aarno:2013}.
Employers of the Simics full-system simulator include IBM~\dvtcmdcitebib[p.~12:1,~12:6]{journals:koerner:2009}, NASA~\dvtcmdciteref{web:windriver:2014, web:nasa:2014}, and Lockheed Martin~\dvtcmdciteref{web:miller:2010}.
Additionally, the simulator has a strong academic tradition, being known to operate in over $300$ universities throughout the world~\dvtcmdcitebib[p.~252]{journals:villa:2005}.

% Graphics Virtualization
\subsection{Graphics Virtualization}
\label{sec:previousresearch_graphicsvirtualization}
There are a number of ways of virtualizing GPUs in system simulators, a few of which accommodate hardware acceleration, but fewer that suit all needs.
It is therefore important to balance required simulation level of detail with performance requirements.
As such, methodologies with varying simulatory accuracy present themselves, from slow low-level instruction set modeling to fast high level paravirtualization.
Summaries of viable strategies are presented below.

% GPU Modeling
\paragraph{GPU Modeling}
\label{par:previousresearch_graphicsvirtualization_gpumodeling}
Some may consider developing a full-fletched GPU model, that is, virtualizing the GPU ISA.
Such methodologies may be appropriate for the purposes of low-level development close to GPU hardware.
For example, one might imagine the scenario of driver development for next-generation GPUs.

However, the development of GPU models, similar to that of common architectural model development for the Simics full-system simulator, incurs a number of flaws.
The first of these flaws encompass estimated development costs reaching unsustainable levels, due to GPU hardware often being poorly documented~\dvtcmdcitebib{inproceedings:lagarcavilla:2007}, on the contrary to CPU architectures.
Furthermore, modeling massively parallelized GPU technology on CPUs induce high costs rendering the methodology less preferable for development requiring anything but slow simulation speed.

% PCI Passthrough
\paragraph{PCI Passthrough}
\label{par:previousresearch_graphicsvirtualization_pcipassthrough}
PCI~passthrough technologies allow virtual systems first-hand access to host machine devices~\dvtcmdciteref{web:jones:2009}.
The direct contact with host system devices accommodated by these technologies enable fully-fledged hardware accelerated workloads.
Yet the methodology suffers from several disadvantages, such as requiring dedicated hardware, causing the host system to lose access to devices during the course of simulation.
In terms of GPU virtualization, this would induce the necessity of multiple graphics cards to the host system.
Additionally, and mayhaps the gratest flaw of passthrough technologies, is the requirement of modifying the simulation target to utilize host hardware; effectively restricting what systems may be simulated.
This restriction encompasses the utilization of corresponding device drivers to the host system, rendering the methodology inflexible in terms of GPU virtualization diversity.

% Paravirtualization
\paragraph{Paravirtualization}
\label{par:previousresearch_graphicsvirtualization_paravirtualization}
At a higher level of abstraction, there is the option of virtualization by paravirtualization.
By selectively modifying target system, we may control the inner workings of system attributes and add functionality such as graphics hardware support.
For graphics acceleration, such a system attribute may be a graphics library or a kernel driver (see figure \ref{fig:overview}).

Inherent by higher abstraction, paravirtualization may be relatively cost-effective in comparison to device modeling.
Additionally, by selectively modifying at the graphics library software level, there is no need for users to modify the application they wish to accelerate.
Furthermore, by utilizing fast communications channels, one may accommodate for significant performance gains when compared to networking solutions (see section \ref{sec:proposedsolutionandimplementation_simicspipe}).
Unfortunately, paravirtualization is not without inherent flaws.
In particular, a paravirtualized graphics library may be expensive to maintain as frameworks evolve and specifications change.
Additionally, paravirtualized methodologies requires modification of target systems; albeit not necessarily being a defect as a paravirtualized framework may still accelerate unmodified target applications.

For the purposes of graphics acceleration in a virtual platform, paravirtualization is a decent levelling of benefits and drawbacks, and is therefore considered a suitable candidate for accelerating graphics in the Simics full-system simulator.

%% % Virtual Time
%% \subsection{Virtual Time}
%% \label{sec:previousresearch_virtualtime}
%% In terms of system simulation, time often becomes abstract; since it is not necessarily the same for an observer outside of the simulation as that of an observer from the inside.
%% The variance in virtual time, as compared to that of real-world time, is called 'simulation slowdown' and may reach orders of magnitude faster than that of real-world time, or likewise orders of magnitude slower.

%% The concepts of real-world and virtual time are particularly important when considering performance measurements.
%% When attempting to establish some sort of measurement in a full-system simulator, such as Simics, one must contemplate what type of time is relevant to the study being performed.
%% For graphics acceleration of real-time applications, it is likely that the real-world wall clock is the primary point of reference (see section \ref{sec:threatstovalidity_platformprofiling} for an elaboration on how time measurement is performed for the sake of this study).
%% However, there are cases in which virtual time is worthwhile to profile, such as the performance of virtual system drivers.

%% \subsection{GPU Architecture}
%% \label{sec:previousresearch_gpuarchitecture}
%% GPUs are massively parallel numeric computing processors often used for 3D graphics acceleration.
%% While CPUs are designed to maximize sequential performance, GPUs are designed to maximize floating-point operations per second throughput; originally required for the floating point linear algebra often needed by 3D graphics.
%% Additionally, the continuous need for faster processing units, slowed down by the heat dissipation issues limiting clock frequency since 2003~\dvtcmdcitebib{publications:kirk:2010}, has driven the utilization of GPUs for general purpose workloads.

%% Generally, CPUs are designed to optimize the execution of an individual thread.
%% In order to facilitate sequential performance, the processing pipeline is designed for low-latency operations; including thorough caching methodologies and low-latency arithmetic units.
%% This design philosophy is often referred to as latency-oriented design, since it strives for low-latency operations to accommodate high performance of individual threads~\dvtcmdcitebib{publications:kirk:2010}.

%% Meanwhile, GPUs are designed to maximize the the throughput of a large number of threads; having less regard for the performance of individual threads.
%% As such, GPUs do not prioritize caches or other low-latency optimizations like CPUs, but aim to conceal overhead induced by memory references or arithmetic by the execution of many threads, which may perform in place during arithmetic or memory operations.
%% Such design is often referred to as throughput-oriented design~\dvtcmdcitebib{publications:kirk:2010}.

%% The differing design philosophies of CPU and GPU units are so fundamentally different that they are largely incompatible in terms their workloads, as explained by Kirk and Hwu~\dvtcmdcitebib{publications:kirk:2010}.
%% As such, programs that feature few threads, CPUs with lower operation latencies may perform better than GPUs; whereas a program with a large number of threads may fully utilize the higher execution throughput of GPUs~\dvtcmdcitebib{publications:kirk:2010}.

%% The introduction of a number of CPU-oriented optimizations for simulating GPU-bound workloads on CPUs has made it possible to simulate such kernels several times faster than traditional simulation.
%% Although orders of magnitudes slower, such optimizations may ease the simulation of GPU workloads on CPUs, as indicative by some studies~\dvtcmdcitebib{papers:nilsson:2013}.
%% However, without hardware-assisted virtualization, the execution of GPU workloads on CPUs quickly becomes unfeasible; inducing the need of more advanced graphics simulation methodologies.

%% \subsection{OpenGL ES}
%% \label{sec:previousresearch_opengles}
%% OpenGL~ES is an API for 3D-graphics on an assortment of embedded systems, such as mobile devices or vehicle displays~\dvtcmdcitebib{publications:munshi:2008}.
%% The OpenGL~ES set of APIs is developed by Khronos, the same consortium responsible for the development of the OpenGL APIs, which - unlike OpenGL for embedded systems - is intended for desktop graphics~\dvtcmdcitebib{publications:wright:2010}.
%% The OpenGL~ES APIs are traditionally derived from the standard OpenGL APIs, and are thus similar in appearance albeit more limited~\dvtcmdcitebib{publications:wright:2010}.

%% The OpenGL~ES~$2.0$ API is selected for use due to its programmable shaders and reduced function set, in addition to accelerated support for the API in the Android emulator.

%% The OpenGL~ES specification is intended to adhere to the following specifications, in relation to the original OpenGL APIs~\dvtcmdcitebib{publications:munshi:2008}:
%% \begin{itemize}[noitemsep]
%%         \item Reduce complexity, but attempt maintain compatibility with OpenGL when possible.
%%         \item Optimize power consumption for embedded devices.
%%         \item Incorporate a set of quality specifiers into the OpenGL~ES specification. This includes minimum quality specifiers for image quality into the standard; accommodating for limited screen sizes in embedded systems.
%% \end{itemize}

%% OpenGL~ES~$2.0$ consists of two Khronos specifications; being the OpenGL~ES~$2.0$ API specification and the OpenGL~ES Shading Language Specification~\dvtcmdcitebib{publications:munshi:2008}.
%% Being derived from the OpenGL ~$2.0$ specification~\dvtcmdcitebib{publications:wright:2010}, OpenGL~ES~$2.0$ supports programmable shaders and is no longer encumbered by the fixed functionality that characterized earlier versions of the OpenGL and OpenGL~ES APIs~\dvtcmdcitebib{publications:munshi:2008}; making the API a modern contestant amongst a variety of applications on a range of platforms, such as the Android and iOS operating systems~\dvtcmdcitebib{publications:wright:2010}, popular on modern smartphones.
