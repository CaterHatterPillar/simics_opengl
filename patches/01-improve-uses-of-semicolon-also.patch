Improve uses of semicolon. Also, minor language improvements

From: Erik Carstensen <erik.carstensen@intel.com>


---
 src/conclusion.tex         |   16 ++++++++--------
 src/introduction.tex       |    6 +++---
 src/methodsandresults.tex  |   44 ++++++++++++++++++++++----------------------
 src/previousresearch.tex   |    8 ++++----
 src/problemformulation.tex |   10 +++++-----
 5 files changed, 42 insertions(+), 42 deletions(-)

diff --git a/src/conclusion.tex b/src/conclusion.tex
index 231645a..caa8394 100644
--- a/src/conclusion.tex
+++ b/src/conclusion.tex
@@ -3,28 +3,28 @@
 % Conclusion
 \section{Conclusion}
 \label{sec:conclusion}
-In the \nameref{sec:results}~section, we have established strengths and weaknesses of paravirtualized graphics in the Simics full-system simulator; most notably the bottleneck introduced by the overhead of magic instructions.
+In the \nameref{sec:results}~section, we have established strengths and weaknesses of paravirtualized graphics in the Simics full-system simulator; most notably, the bottleneck introduced by the overhead of magic instructions.
 As such, we have confirmed original suspicions through the use of our benchmarks.
 Thus, our study has identified the performance bottleneck inherent in great numbers of paravirtualized function invocations for magic instructions.
 
 Furthermore, compiled results have showcased great improvements for computationally intensive graphics, as demonstrated by the Julia fractal benchmark, compared to its software rasterized Simics counterpart.
-As such, we have accelerated graphics by up to $34$ times; reducing frame time from that of \dvtcmdfirstline{simicsjulia900.dat.avg}~ms to the real-time feasible count of \dvtcmdfirstline{parajulia900.dat.avg}~ms.
+As such, we have accelerated graphics by up to $34$ times, reducing frame time from that of \dvtcmdfirstline{simicsjulia900.dat.avg}~ms to the real-time feasible count of \dvtcmdfirstline{parajulia900.dat.avg}~ms.
 It is likely that this performance improvement would be orders of magnitude greater for virtual platforms that do not utilize hardware-assisted virtualization, such as when using Simics to simulate other systems than x86-compatible ones, or when using breakpoints.
-Accordingly, our experiment has identified the potential of using paravirtualization for the means of accelerating graphics to that of real-time performance; testimonial to the results presented by Lagar-Cavilla et al. in their work on using paravirtualization to accelerate graphics~\dvtcmdcitebib{inproceedings:lagarcavilla:2007}.
-Additionally, beyond that of accelerated graphics, results indicates performance improvements in terms of maximum frametimes; inducing significantly improved standard deviation.
+Accordingly, our experiment has identified the potential of using paravirtualization for the means of accelerating graphics to that of real-time performance, testimonial to the results presented by Lagar-Cavilla et al. in their work on using paravirtualization to accelerate graphics~\dvtcmdcitebib{inproceedings:lagarcavilla:2007}.
+Additionally, beyond that of accelerated graphics, results indicates performance improvements in terms of maximum frametimes, inducing significantly improved standard deviation.
 In line with stable frame rates being prerequisites for real-time applications, this further indicate, in coagency with reduced frametimes, the feasibility of utilizing paravirtualized methodologies for the purposes of accelerating graphics within virtual platforms.
 
-As to summarize; we have presented a solution for graphics acceleration implemented in the Simics full-system simulator by the means of paravirtualization.
+To summarize: We have presented a solution for graphics acceleration implemented in the Simics full-system simulator by the means of paravirtualization.
 The end-result is a solution which may generate libraries imitating EGL- and OpenGL~ES~$2.0$ libraries.
 We may effectively spy on application EGL utilization, without inhibiting said exchange, allowing unmodified OpenGL applications to be accelerated from within the simulation target.
 The implementation communicates by the means of low-latency magic instructions with no limit as to how much memory may be shared.
 As such, throughout this document, we have tackled and presented several issues pertaining to paravirtualized graphics acceleration.
 For the purposes of performance testing, we have developed benchmarks with the distinct purpose of highlighting solution weaknesses and strengths.
-We have presented an analysis of benchmarking results and presented the benefits and drawbacks of paravirtualization as means to graphics acceleration in virtual platforms; backed by hard data stressing key points in the implementation, with the purpose of identifying both strengths and weaknesses.
+We have presented an analysis of benchmarking results and presented the benefits and drawbacks of paravirtualization as means to graphics acceleration in virtual platforms, backed by hard data stressing key points in the implementation, with the purpose of identifying both strengths and weaknesses.
 Accordingly, the findings of this paper has contributed to our understanding of the difficulties facing paravirtualized graphics acceleration, and established the feasibility of using paravirtualization to accelerate graphics in virtual platforms to that of real-time qualities.
 
-As to conclude; this paper has demonstrated performance improvements by accelerating graphics using paravirtualization.
-Induced benefits are performance improvements of up to $34$ times; speculating in much larger benefits in non-hardware-assisted virtualized use-cases.
+To conclude: This paper has demonstrated performance improvements by accelerating graphics using paravirtualization.
+Induced benefits are performance improvements of up to $34$ times, speculating in much larger benefits in non-hardware-assisted virtualized use-cases.
 Magic instruction overhead has been identified as the main performance bottleneck.
 As such, a possible drawback of graphics paravirtualization is a weakness to large amounts of framework invocations.
 Thus, this paper claims paravirtualization as a successful formula for system simulator graphics acceleration, and suggests utilizing high-level paravirtualization to accelerate graphics in virtual platforms.
diff --git a/src/introduction.tex b/src/introduction.tex
index a3df47c..0f95337 100644
--- a/src/introduction.tex
+++ b/src/introduction.tex
@@ -5,12 +5,12 @@
 \label{sec:introduction}
 Virtual platforms are becoming an important tool in the software industry in order to provide cost-effective time-to-market gains and meet the ever-shortening product life-cycles~\cite{journals:magnusson:2002, journals:yi:2006}.
 Virtual platforms deliver these time-to-market benefits in two major ways.
-First of all, virtual platforms enable pre-silicon development, that is; software development that may begin prior to next-generation hardware being available~\dvtcmdcitebib[p.~52]{journals:magnusson:2002}.
+First of all, virtual platforms enable pre-silicon development; that is, software development that may begin prior to next-generation hardware being available~\dvtcmdcitebib[p.~52]{journals:magnusson:2002}.
 Secondly, virtual platforms may provide additional development tools compared to working with actual hardware.
 For example, some virtual platforms allow simulated systems, often known as simulation targets, to be stopped synchronously without affecting timing or states of the target software~\dvtcmdcitebib[p.~61]{inproceedings:yu:2012}, and allow investigation of race conditions and other parallel programming issues~\dvtcmdcitebib[p.~1]{inproceedings:schumacher:2010, publications:leupers:2010}.
 Additionally, such platforms may allow intricate inspection of simulated hardware, such as memory, caches, and registers~\dvtcmdcitebib[p.~54]{journals:magnusson:2002}.
 Some virtual platforms provide advanced features such as reverse execution (the ability to run a simulation backwards) and checkpointing (functionality to save- and restore the state of a simulation).
-These features are useful for debugging and testing a diverse range of software; from firmware to end-user applications~\dvtcmdcitebib[p.~25]{publications:leupers:2010}.
+These features are useful for debugging and testing a diverse range of software, from firmware to end-user applications~\dvtcmdcitebib[p.~25]{publications:leupers:2010}.
 
 There are several techniques to provide fast functional virtual platforms that are running CPU workloads.
 Typical methods include interpretation~\dvtcmdcitebib[p.~35]{journals:smith:2005}, just-in-time compilation~\dvtcmdcitebib[p.~24,~25]{journals:aarno:2013}, and hardware-assisted virtualization~\dvtcmdcitebib[p.~24,~25]{journals:aarno:2013, publications:leupers:2010}.
@@ -34,7 +34,7 @@ Effectively, this entails modifying the virtual machine to be similar, but not i
 As such, one may simplify the virtualization process by neglecting some hardware compatibility~\dvtcmdcitebib[p.~1]{inproceedings:youseff:2006}.
 
 This paper comprises an investigation of OpenGL graphics paravirtualization in the Simics full-system simulator.
-The work presents an implementation of accelerated OpenGL~ES~$2.0$ graphics; using magic instructions as a communications bridge between target and host systems.
+The work presents an implementation of accelerated OpenGL~ES~$2.0$ graphics, using magic instructions as a communications bridge between target and host systems.
 Additionally, we present performance benchmarks stressing important attributes of the devised solution.
 We then evaluate the performance of the accelerated platform with regular software rasterization.
 Furthermore, our study identifies performance bottlenecks that may obstruct paravirtualized real-time graphics.
diff --git a/src/methodsandresults.tex b/src/methodsandresults.tex
index 3a1ec46..2196032 100644
--- a/src/methodsandresults.tex
+++ b/src/methodsandresults.tex
@@ -12,7 +12,7 @@ These components, along with elaboration of the methodologies accomodating them,
 \label{sec:proposedsolutionandimplementation_openglabigeneration}
 For the purposes of ensuring scalability of the solution during development, a set of scripts automating the generation of library source code is used to compile the majority of target- and host system libraries.
 As such, a large amount of the OpenGL function definitions encoded and decoded by the these libraries are produced by this tool.
-For this, we use a \texttt{Python} program that, from framework specification files detailing function signatures and argument attributes, generate both headers and source files in \texttt{C}; thus constructing the target OpenGL and EGL frameworks, along with the corresponding host decoding libraries.
+For this, we use a \texttt{Python} program that, from framework specification files detailing function signatures and argument attributes, generate both headers and source files in \texttt{C}, thus constructing the target OpenGL and EGL frameworks, along with the corresponding host decoding libraries.
 The tool generates all but the methods that need special treatment (due to state saving) and may thus generate methods with return values and inout arguments.
 
 \subsection{Target System Libraries}
@@ -23,8 +23,8 @@ As may be derived from the name, the target system libraries run on the simulati
 
 Accordingly, the target system libraries implement the EGL and OpenGL~ES~$2.0$ APIs and lures whatever application it is being linked to that it is, in fact, the expected platform libraries.
 Given that the target system libraries adheres to the OpenGL headers defined in the system, the application is na\"{\i}ve in terms of its paravirtualized status.
-The interplay with the original OpenGL~ES headers also results in the solution adhering to the platform-dependent type definition, flags, and constants; as originally defined by Khronos.
-However, instead of communicating with the platform windowing system (in terms of EGL) and the graphics device (in terms of OpenGL) - and instructing said device in accordance to the user; the target system libraries serialize the given command stream and forwards it to the simulation host.
+The interplay with the original OpenGL~ES headers also results in the solution adhering to the platform-dependent type definition, flags, and constants, as originally defined by Khronos.
+However, instead of communicating with the platform windowing system (in terms of EGL) and the graphics device (in terms of OpenGL) -- and instructing said device in accordance to the user; the target system libraries serialize the given command stream and forward it to the simulation host.
 However, the transmission of the command stream is not necessarily performed at once, or in the designated order, due to the formation of the OpenGL~ES~$2.0$ framework.
 This complex of problems involve uncertainties of the proportion of argument data, as size is not necessarily given by the user or apperent at that time.
 As such, certain serialization may have to be delayed until further information surrounding the argument dimensions have been relayed to the OpenGL library.
@@ -67,8 +67,8 @@ As such, the target system libraries are effectively performing a man-in-the-mid
 \subsection{Simics Pipe}
 \label{sec:proposedsolutionandimplementation_simicspipe}
 The Simics pipe constitutes the target-to-host communications channel in Simics.
-As such, it is responsible for transferring a serialized command stream to- and from the simulation host.
-In order to do this, the pipe requires a way to exchange information with the outside world; a recurring issue in terms of virtual platforms.
+As such, it is responsible for transferring a serialized command stream between target software and simulation host.
+In order to do this, the pipe requires a way to exchange information with the outside world.
 
 There may be reasons as to why one would like to escape the simulation and resume execution in the real world.
 Such a scenario would be a debugging breakpoint, to share data in-between target and host systems, or for any reason modify the simulation state.
@@ -77,18 +77,18 @@ There are a number of ways to communicate with the outside world (including the
 The magic instruction is a concept used to denote a \dvtcmdcodeinline{nop}-type instruction, meaning an instruction that would have no effect if run on the target architecture (such as \dvtcmdcodeinline{xchg ebx, ebx} on the x86), which, when executed on the simulated hardware in a virtual platform, invokes a callback-method in the simulation host~\dvtcmdcitebib[p.~32]{publications:leupers:2010}.
 An advantage of this methodology is an often negligible invocation cost, as the context switch is often instant from the perspective of the target system~\dvtcmdcitebib[p.~131]{journals:rechistov:2013}.
 Furthermore, being a greatly desirable attribute, magic instructions require no modification of the target system.
-In effect, implementation of magic instructions requires replacing one- or more instructions in the target instruction set; thereby making the magic instruction platform-dependent.
+In effect, implementation of magic instructions requires replacing one or more instructions in the target instruction set, thereby making the magic instruction platform-dependent.
 However, the solution is often designed to only respond to magic instructions wherein a certain magic number, sometimes called a 'leaf number'~\dvtcmdcitebib[p.~131]{journals:rechistov:2013}, is present in an arbitrary processor register.
 
 Due to the inherent performance demands brought on by serialization of real-time graphics invocations, magic instructions are a suitable candidate to exchange information between target host systems.
 Magic instructions allow for fast, in the pretext of the simulation target - almost instant - escape from the simulation context, and may carry a limited amount of information with it from inside the simulation out into the real world.
-The role of the Simics pipe is comprised of the allocation and maintenance of page locked target memory to accomodate the use of magic instructions; which the Simics pipe uses to relay the starting address of said memory space to the simulation host.
+The role of the Simics pipe is comprised of the allocation and maintenance of page locked target memory to accomodate the use of magic instructions, which the Simics pipe uses to relay the starting address of said memory space to the simulation host.
 
 During a magic instruction, we may write an arbitrary 64-bit address to any register fit for purpose (the number and size of processor registers being the data-sharing bottleneck of the method).
 Not being the first time magic instructions have been used for the purposes of hardware acceleration~\dvtcmdcitebib[p.~32]{publications:leupers:2010}, the Simics Pipe utilizes such methodology, namely the \dvtcmdcodeinline{CPUID} x86 instruction, to carry a lone memory address (the starting address of the serialized command stream) in one of the target system registers.
-The execution of the injected instruction in a simulated processor invokes a callback method in the host side of the Simics Pipe; having effectively escaped the simulation and paused the simulation state.
+The execution of the injected instruction in a simulated processor invokes a callback method in the host side of the Simics Pipe, having effectively escaped the simulation and paused the simulation state.
 Knowing the occurrence of a magic instruction with the corresponding leaf number, one may assume the existence of a target memory address in the simulated target CPU register, as agreed upon.
-Note that, at this point, the retrieved address is in the format of a target system virtual address; the destination of which is unknown to the simulation host.
+Note that, at this point, the retrieved address is in the format of a target system virtual address, the destination of which is unknown to the simulation host.
 As such, this address need be translated in order to retrieve the package contents said memory address points to.
 
 \begin{figure}
@@ -109,7 +109,7 @@ This is the methodology used to ensure that the physical memory space, referred
 Other methods to achieve this include repeatedly 'polling' the corresponding memory pages in the target system.
 
 Furthermore, and again induced by the unorthodox circumvention of the virtual memory paradigm, it is probable that the multiple memory pages making out particularly large serialized command streams, such as the transmission of vertex or texture data, are not consecutively aligned in physical memory, although guaranteed to be continuous blocks in terms of virtual memory.
-As such, the physical addresses of memory pages must be continuously retrieved and translated on a per-page basis; effectively 'traversing' the virtual memory table (see figure \ref{fig:virtualmemory}).
+As such, the physical addresses of memory pages must be continuously retrieved and translated on a per-page basis, effectively 'traversing' the virtual memory table (see figure \ref{fig:virtualmemory}).
 This can be done in a trivial manner by simply iterating the original virtual address with the (target) page size.
 In our case, $4096$ bytes.
 Naturally, said process must be performed regardless of data being read or written to-/from the intended (physical) memory space.
@@ -171,7 +171,7 @@ The specifics of these instances are described along with the benchmarks below.
 \index{Chess benchmark}
 The 'Chess' benchmark is developed for the purposes of stressing the latency in-between target - and host systems.
 It is so named because of the chess-like tileset the graphics kernel produces.
-The benchmark is designed to perform a multitude of OpenGL~ES~$2.0$ library invocations per frame; in which each invocation is relatively lightweight in execution and carry a small amount of data argument-wise.
+The benchmark is designed to perform a multitude of OpenGL~ES~$2.0$ library invocations per frame, in which each invocation is relatively lightweight in execution and carries a small amount of data in its arguments.
 In the Chess benchmark, this is achieved by rendering a grid of colored (black or white, in order to adhere to the chess paradigm) rectangles where each tile is represented by four two-dimensional vertices in screen-space, in addition to six indices outlining the rectangular shape.
 Since the vertices are already transformed into screen-space, the graphics kernel need perform no additional transformation, adhering to the desired lightweight behavior of each kernel invocation.
 Additionally, the tileset vertices and indices are pre-loaded into OpenGL vertex- and index element buffers, so that a lone buffer identifier may be carried over in-place of the heavier vertex set load.
@@ -180,7 +180,7 @@ Effectively, this means that, for each tile, the benchmark need only bind a vert
 
 For each frame rendered, depending on the number of drawn tiles, the solution will perform a large number of magic instructions.
 This induces a high utilization of the Simics Pipe, which is intended to stress magic instruction overhead (section \ref{sec:results_magicinstructionoverhead}).
-The repeated invocation of lesser draw calls is representative of common usage of drawing a multitude of shapes with OpenGL, such as a user interface. Additionally, the number of tiles being computed is easily modifiable; rendering the benchmark scalable for the purposes of the experiment described in this document. As such, said benchmark is considered suitable for the purpose of representing a large number of graphics invocations using OpenGL~ES~$2.0$.
+The repeated invocation of lesser draw calls is representative of common usage of drawing a multitude of shapes with OpenGL, such as a user interface. Additionally, the number of tiles being computed is easily modifiable, rendering the benchmark scalable for the purposes of the experiment described in this document. As such, said benchmark is considered suitable for the purpose of representing a large number of graphics invocations using OpenGL~ES~$2.0$.
 
 We perform the Chess benchmark with $60\times60$, $84\times84$, and $118\times118$ tiles, which entails roughly $9\times60\times60$, $9\times84\times84$, and $9\times118\times118$ magic instructions per frame.
 
@@ -189,7 +189,7 @@ We perform the Chess benchmark with $60\times60$, $84\times84$, and $118\times11
 \label{par:experimentalmethodology_benchmarking_benchmarkjulia}
 \index{Julia fractal benchmark}
 The 'Julia' benchmark is developed for the purposes of stressing computational intensity in software-rasterized and paravirtualized platforms.
-It is so named due to the kernel calculating the Julia fractal; the texturing and frame-wise seeding of which gives the benchmark it's distinct look.
+The kernel calculates the Julia fractal, the texturing and frame-wise seeding of which gives the benchmark its distinct look.
 The benchmark is designed to perform a lone computationally intensive graphics kernel invocation, which will stress the computational prowess of the profiled platform.
 The case is selected for use as the computation of a fractal is trivially scalable in terms of complexity, by modifying the number of iterations the fractal algorithm performs, and is thus considered suitable for profiling of computationally intensive graphics kernels.
 
@@ -203,7 +203,7 @@ This is often the case if the simulation has outside dependencies of some sort.
 Naturally, it is so in terms of real-time interaction and rendering.
 
 In order to profile elapsed frametimes, profiling must take place outside of the simulation.
-One way of achieving this is to listen in on activity passing through a target serial port; being a traditional front-end to the machine.
+One way of achieving this is to listen in on activity passing through a target serial port; this is a traditional front-end to the machine.
 In this way, the simulator is instructed to listen in on, and set a simulation breakpoint at the occurrence of, a specialized sequence of bytes being written (via a serial console) to a UART serial port.
 This is the method we use to profile frametime performance in Simics.
 
@@ -212,7 +212,7 @@ Such overhead may be induced file descriptors not immediately transmitting a con
 We have measured this cost to be on average \dvtcmdfirstline{profile.dat.avg}~ms, with a minimum and maximum elapsed time of \dvtcmdfirstline{profile.dat.min} and \dvtcmdfirstline{profile.dat.max}, respectively, adhering to a standard deviation of \dvtcmdfirstline{profile.dat.std}.
 From these measurements, we may deduce that profiling overhead cost may occasionally be volatile.
 However, with a standard deviation of \dvtcmdfirstline{profile.dat.std} ms, slightly below that of the average, such large deviation is to be quite rare.
-If not specified otherwise, all results have taken into account the average of this profiling cost; being \dvtcmdfirstline{profile.dat.avg}~ms.
+If not specified otherwise, all results have taken into account the average of this profiling cost, \dvtcmdfirstline{profile.dat.avg}~ms.
 
 \subsection{Results}
 \label{sec:results}
@@ -315,28 +315,28 @@ From the data visualized in figure \ref{fig:histogramssimicsparachess}, we may o
 The right-hand side of the graph, while also showcasing impaired performance induced by paravirtualization, visualize a decrease in sample density distribution.
 This is supported by the data presented in table \ref{tab:keyvalpara}.
 
-Based on the data summarized in table \ref{tab:keyvalsimics} and comparing said data to that of table \ref{tab:keyvalpara}, we may observe that the software rasterized solution outperforms its paravirtualized counterpart; regardless of number of tiles rendered.
+Based on the data summarized in table \ref{tab:keyvalsimics} and comparing said data to that of table \ref{tab:keyvalpara}, we may observe that the software rasterized solution outperforms its paravirtualized counterpart, regardless of number of tiles rendered.
 The only redeeming attributes the paravirtualized solution brings to the table is a decrease in standard deviation.
 % When comparing these results to the uncompromised hardware accelerated counterpart on the host machine (see figure \ref{fig:histogramshost}), we may observe - albeit considerably less prominent - an adherence to the single-peak behavior in the distribution of the sample density.
 
 We devised the Chess benchmark to locate any bottlenecks related to the number of paravirtualized invocations, which was predicted a bottleneck during the pilot study.
-Evidently, the prediction of a target-to-host communication letency issue has been confirmed; arguably identifying the weakness of graphics paravirtualization in the Simics full-system simulator.
+Evidently, the prediction of a target-to-host communication letency issue has been confirmed, arguably identifying one weakness of graphics paravirtualization in the Simics full-system simulator.
 
 In Simics, magic instructions incur a context switch cost when exiting the simulation and beginning execution in the real world.
-This affects the performance by forcing the simulation to no longer be executed in native mode; inhibiting the simulatory performance improvements granted by hardware-assisted virtualization.
-It also entail Simics no longer being able to utilize just-in-time compilation to speed up execution; having to rely on regular code interpretation.
+This affects the performance by forcing the simulation to no longer be executed in native mode, inhibiting the simulatory performance improvements granted by hardware-assisted virtualization.
+It also entails Simics no longer being able to utilize just-in-time compilation to speed up execution, having to rely on regular code interpretation.
 As such, in great numbers, magic instructions may greatly affect performance.
 
 We performed further study into this matter to establish what those overhead costs may be.
-To do this, we measured elapsed time for escaping simulation $1000$ times using magic instructions; collecting minimum (\dvtcmdfirstline{magicinstrprofileall.dat.min}), maximum (\dvtcmdfirstline{magicinstrprofileall.dat.max}), average (\dvtcmdfirstline{magicinstrprofileall.dat.avg}), the standard deviation thereof (\dvtcmdfirstline{magicinstrprofileall.dat.std}), time to do so.
+To do this, we measured elapsed time for escaping simulation $1000$ times using magic instructions, collecting minimum (\dvtcmdfirstline{magicinstrprofileall.dat.min}), maximum (\dvtcmdfirstline{magicinstrprofileall.dat.max}), average (\dvtcmdfirstline{magicinstrprofileall.dat.avg}), the standard deviation thereof (\dvtcmdfirstline{magicinstrprofileall.dat.std}), time to do so.
 From these findings, we may conclude that the execution of $1000$ magic instructions is expected to induce an average overhead of \dvtcmdfirstline{magicinstrprofileall.dat.avg}~ms per magic instruction.
 Indeed, these findings indicate that magic instruction overhead could ver well account for the majority of the elapsed average frametimes when paravirtualized in Simics.
 
-In figure \ref{fig:histogramssimicsparajulia}, we may observe double- to triple peak behavior in the distribution of the sample density; both in software rasterized and paravirtualized platforms.
+In figure \ref{fig:histogramssimicsparajulia}, we may observe double to triple peak behavior in the distribution of the sample density, both in software rasterized and paravirtualized platforms.
 What causes this behavior is unclear, as frame-to-frame branching in the fractal algorithm is minor and ought not cause such a variance.
 
 The Julia benchmark is incorporated into the experiment to establish how the paravirtualized solution performed under computational stress, which is where benefits induced by hardware acceleration should be made apperent.
-Using this benchmark, we highlight weaknesses in Simics software rasterization, with frame times well above the two second mark; with corresponding maximum frame time in the paravirtualized Simics platform measuring up to to a mere \dvtcmdfirstline{parajulia900.dat.max} ms.
+Using this benchmark, we highlight weaknesses in Simics software rasterization, with frame times well above the two second mark; the corresponding maximum frame time in the paravirtualized Simics platform measuring up to to a mere \dvtcmdfirstline{parajulia900.dat.max} ms.
 As visualized in figure \ref{fig:histogramssimicsparajulia}, we showcase considerable performance improvements and - in turn - identify the capabilities of graphics paravirtualization in the Simics full-system simulator.
 
 % Albeit the hardware accelerated host profiling (see figure \ref{fig:histogramshost}) may, however minor, suggest such a pattern; it is by all means not significant.
diff --git a/src/previousresearch.tex b/src/previousresearch.tex
index 0feac79..ad48d29 100644
--- a/src/previousresearch.tex
+++ b/src/previousresearch.tex
@@ -16,7 +16,7 @@ QEMU ('Quick~Emulator') is an open-source virtual platform described as a full s
 As such, QEMU may run unmodified target software such as OSs, drivers, and other applications~\dvtcmdcitebib[p.~1]{inproceedings:bellard:2005}.
 The platform is widely used in academia, and is the subject of several articles and reports cited throughout this document.
 Additionally, QEMU powers the Android emulator, which helps mobile developers bring about software for the Android OS.
-Using QEMU, the Android emulator accelerates OpenGL~ES~$1.1$ and $2.0$; granting developers significant performance boosts~\dvtcmdciteref{web:ducrohet:2012:afasteremulator}.
+The Android emulator accelerates OpenGL~ES~$1.1$ and $2.0$, granting developers significant performance boosts~\dvtcmdciteref{web:ducrohet:2012:afasteremulator}.
 
 Other promising GPU virtualization projects include the Virgil3D-project~\dvtcmdciteref{technicaldocs:qemudevel:2014}.
 As described at the project homepage, the project strives to create a virtual GPU which may utilize host hardware to accelerate 3D rendering.
@@ -28,7 +28,7 @@ One such example is VMware,~Inc.~\dvtcmdciteref{technicaldocs:vmware:2014}.
 \subsection{Simics}
 \label{sec:simics}
 Simics is a full-system simulator developed by Intel\circledR\ and sold through Intel\circledR 's subsidiary Wind~River~Systems,~Inc.
-Simics was developed by the simulation group at the Swedish Institute of Computer Science; the first instance of an academic group running an unmodified OS in an entirely simulated environment.
+Simics was developed by the simulation group at the Swedish Institute of Computer Science, which was the first academic group to run an unmodified OS in an entirely simulated environment.
 The product was was commercially launched by Virtutech in $1998$~\dvtcmdcitebib{journals:magnusson:2013} and subsequently acquired by Intel\circledR\ in $2010$~\dvtcmdciteref{web:miller:2010}.
 
 As an architectural simulator, Simics' primary client group is software and systems developers that produce software for complex systems involving software and hardware interaction~\dvtcmdcitebib{journals:aarno:2013}.
@@ -38,7 +38,7 @@ Simics also feature advanced functionalities adhering to the deterministic natur
 
 The ability to simulate the entirety of an unmodified software stack has led to Simics being used to simulate a variety of systems including, but not limited to, single-processor embedded boards, multiprocessor servers, and heterogeneous telecom clusters~\dvtcmdcitebib{journals:aarno:2013}.
 Employers of the Simics full-system simulator include IBM~\dvtcmdcitebib[p.~12:1,~12:6]{journals:koerner:2009}, NASA~\dvtcmdciteref{web:windriver:2014, web:nasa:2014}, and Lockheed Martin~\dvtcmdciteref{web:miller:2010}.
-Additionally, the simulator has a strong academic tradition; being known to operate in over $300$ universities throughout the world~\dvtcmdcitebib[p.~252]{journals:villa:2005}.
+Additionally, the simulator has a strong academic tradition, being known to operate in over $300$ universities throughout the world~\dvtcmdcitebib[p.~252]{journals:villa:2005}.
 
 % Graphics Virtualization
 \subsection{Graphics Virtualization}
@@ -51,7 +51,7 @@ Summaries of viable strategies are presented below.
 % GPU Modeling
 \paragraph{GPU Modeling}
 \label{par:previousresearch_graphicsvirtualization_gpumodeling}
-Some may consider developing a full-fletched GPU model; that is, virtualizing the GPU ISA.
+Some may consider developing a full-fletched GPU model, that is, virtualizing the GPU ISA.
 Such methodologies may be appropriate for the purposes of low-level development close to GPU hardware.
 For example, one might imagine the scenario of driver development for next-generation GPUs.
 
diff --git a/src/problemformulation.tex b/src/problemformulation.tex
index 50aba8b..17b9858 100644
--- a/src/problemformulation.tex
+++ b/src/problemformulation.tex
@@ -8,19 +8,19 @@ As such, this study concerns investigating the performance of paravirtualized gr
 This entails investigation, analysis, and development of methods and techniques for efficient communication and execution in the Simics run-time environment.
 
 Accordingly, we devise a paravirtualized solution for graphics acceleration in Simics.
-To accommodate the analysis of benefits and drawbacks of paravirtualized graphics, we devise a benchmark suite; with the goal of locating performance bottlenecks.
+To accommodate the analysis of benefits and drawbacks of paravirtualized graphics, we devise a benchmark suite with the goal of locating performance bottlenecks.
 The benchmarks are designed to stress latency in target-to-host communication, in addition to computational intensity brought on by complex GPU workloads.
 In coagency with the benchmarks, this study comprises an analysis of the performance of paravirtualized graphics compared to that of traditional software rasterization.
-The objectives of the paper is to evaluate the feasibility of paravirtualization as an approach to accelerate graphics in virtual platforms; along with identifying its strengths and weaknesses.
+The objectives of the paper is to evaluate the feasibility of paravirtualization as an approach to accelerate graphics in virtual platforms, and to identify its strengths and weaknesses.
 
-\hl{In regards to previous work in the area, there is no indication - in academic writing - of existing paravirtualized graphics in a simulator with advanced capabilities such as Simics; featuring deterministic execution, checkpointing and reverse execution.
+\hl{In regards to previous work in the area, there is no indication -- in academic writing -- of existing paravirtualized graphics in a simulator with advanced capabilities such as Simics, featuring deterministic execution, checkpointing and reverse execution.
 Potential performance gains on such a platform are inherently unclear due to these features.}
 Such functionality could simplify debugging, testing, and profiling of applications comprising some GPU-bound workload.
 Entailed by these research gaps, the research questions formulated in this chapter are considered to be lacking in the field.
 
-As such, the study performed for the purposes of this paper is relevant to the field of computer science by expanding upon the the knowledge of graphics acceleration in virtual platforms; in terms of facilitating debugging, testing, and profiling of software dependent on GPU graphics acceleration.
+As such, the study performed for the purposes of this paper is relevant to the field of computer science by expanding upon the the knowledge of graphics acceleration in virtual platforms. Graphics acceleration in a virtual platform is relevant because it facilitates debugging, testing, and profiling of software which dependends on GPU graphics acceleration.
 By these means, this paper contributes to the field of computer science by answering these questions from the perspective of graphics paravirtualization in the Simics full-system simulator.
-Accordingly, the research questions sought to be answered by this paper are presented below.
+This paper seeks to answer the following research questions:
 
 \begin{enumerate}
   \item What constitutes a viable implementation of paravirtualized graphics?
